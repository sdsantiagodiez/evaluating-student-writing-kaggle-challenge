{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Changing working directory to repository path \n",
    "in order to make simpler references to files/folder.\n",
    "\n",
    "Also, adding src folder in the repository to import\n",
    "any code that has been moved to py files for reusability\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "REPOSITORY_PATH = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlgpu2/code/Users/santiago.a.diez/evaluating-student-writing-kaggle-challenge'\n",
    "os.chdir(REPOSITORY_PATH)\n",
    "import sys  \n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from eswkg.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import wandb\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import cuda\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "#from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_essay(essay_id, folder_path = Config.get_file_path(\"train_folder\")):\n",
    "    with open(folder_path + f\"/{essay_id}.txt\") as f:\n",
    "        essay = f.read()\n",
    "    return essay\n",
    "\n",
    "\n",
    "def read_essays(train_txt):\n",
    "    train_txt_file_id, train_txt_file_text = [],[]\n",
    "    for train_txt_file in train_txt:\n",
    "        essay_id = os.path.basename(train_txt_file).rsplit(\".\",1)[0]\n",
    "        essay_folder = os.path.dirname(train_txt_file)\n",
    "\n",
    "        train_txt_file_id.append(essay_id)\n",
    "        train_txt_file_text.append(read_essay(essay_id,essay_folder))\n",
    "    return pd.DataFrame({\"id\":train_txt_file_id, \"text\":train_txt_file_text})\n",
    "\n",
    "\n",
    "def get_essay_entities(essay_text, essay_metadata):\n",
    "    essay_entities = [\"O\"]*len(essay_text.split())\n",
    "    for discourse_type, predictionstring in zip(essay_metadata[\"discourse_type\"],essay_metadata[\"predictionstring\"]):\n",
    "        predictionstring_digits = list(map(int, predictionstring.split()))\n",
    "        \n",
    "        essay_entities[predictionstring_digits[0]] = f\"B-{discourse_type}\"\n",
    "        for predictionstring_digits_index in predictionstring_digits[1:]:\n",
    "           essay_entities[predictionstring_digits_index] = f\"I-{discourse_type}\"\n",
    "    \n",
    "    return essay_entities\n",
    "\n",
    "\n",
    "def tag_essays(essays, essays_metadata):\n",
    "    tagged_essays = pd.DataFrame()\n",
    "    tagged_essays_list = []\n",
    "    for _, essay in essays.iterrows():\n",
    "        essay_id = essay[\"id\"]\n",
    "        essay_text = essay[\"text\"]\n",
    "        essay_metadata = essays_metadata.query(\"id == @essay_id\")\n",
    "        essay_entities = get_essay_entities(essay_text, essay_metadata)\n",
    "\n",
    "        tagged_essays_list.append( \n",
    "            {\n",
    "                \"id\": essay_id,\n",
    "                \"text\": essay_text,\n",
    "                \"entities\": essay_entities\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame.from_dict(tagged_essays_list)\n",
    "\n",
    "\n",
    "def generate_file(generation_func, file_path, generate_file=False, *args):\n",
    "    try:\n",
    "        if generate_file:\n",
    "            generation_func(*args).to_csv(file_path, index=False)\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"{err}, {type(err)}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Unexpected {err}, {type(err)}\")\n",
    "        raise\n",
    "\n",
    "def generate_labels_file(essays_metadata, file_path=Config.get_file_path(\"model_input\")):\n",
    "    label_list = []\n",
    "    label_list.append('O')\n",
    "\n",
    "    for discourse_type in essays_metadata.discourse_type.unique():\n",
    "        label_list.append(f'B-{discourse_type}')\n",
    "        label_list.append(f'I-{discourse_type}')\n",
    "\n",
    "    labels_to_ids = {v:k for k,v in enumerate(label_list)}\n",
    "    ids_to_labels = {k:v for k,v in enumerate(label_list)}\n",
    "    \n",
    "    with open(file_path+\"/label_list.txt\", \"w\") as output:\n",
    "        output.write(str(label_list))\n",
    "        \n",
    "    json.dump(labels_to_ids, open(file_path+\"/labels_to_ids.json\",'w'))\n",
    "    json.dump(ids_to_labels, open(file_path+\"/ids_to_labels.json\",'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving file paths for different folders and files in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = Config.get_all_file_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_metadata = pd.read_csv(file_paths[\"train\"])\n",
    "essays_metadata[['discourse_id', 'discourse_start', 'discourse_end']] = essays_metadata[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n",
    "\n",
    "sample_submission = pd.read_csv(file_paths[\"sample_submission\"])\n",
    "\n",
    "#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "train_txt = glob(file_paths[\"train_folder\"] + \"/*.txt\") \n",
    "test_txt = glob(file_paths[\"test_folder\"] + \"/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>80% of Americans believe seeking multiple opin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>When people ask for advice,they sometimes talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...\n",
       "1  18409261F5C2  80% of Americans believe seeking multiple opin...\n",
       "2  D46BCB48440A  When people ask for advice,they sometimes talk...\n",
       "3  D72CB1C11673  Making choices in life can be very difficult. ...\n",
       "4  DF920E0A7337  Have you ever asked more than one person for h..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_test_essays_file = False\n",
    "essays_file_path = file_paths[\"intermediate\"]+\"/test_text.csv\"\n",
    "\n",
    "test_essays = generate_file(read_essays, essays_file_path, create_test_essays_file, test_txt)\n",
    "\n",
    "print(test_essays.shape)\n",
    "test_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15594, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>Would you be able to give your car up? Having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...\n",
       "1  00066EA9880D  Driverless cars are exaclty what you would exp...\n",
       "2  000E6DE9E817  Dear: Principal\\n\\nI am arguing against the po...\n",
       "3  001552828BD0  Would you be able to give your car up? Having ...\n",
       "4  0016926B079C  I think that students would benefit from learn..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_essays_file = False\n",
    "essays_file_path = file_paths[\"intermediate\"]+\"/train_text.csv\"\n",
    "\n",
    "essays = generate_file(read_essays, essays_file_path, create_essays_file, train_txt)\n",
    "\n",
    "print(essays.shape)\n",
    "essays.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15594, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "      <td>[O, O, B-Position, I-Position, I-Position, I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>Would you be able to give your car up? Having ...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...   \n",
       "1  00066EA9880D  Driverless cars are exaclty what you would exp...   \n",
       "2  000E6DE9E817  Dear: Principal\\n\\nI am arguing against the po...   \n",
       "3  001552828BD0  Would you be able to give your car up? Having ...   \n",
       "4  0016926B079C  I think that students would benefit from learn...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "2  [O, O, B-Position, I-Position, I-Position, I-P...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Position, I-Position, I-Position, I-Positio...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_essay_entities_file = False\n",
    "essay_entities_file_path = file_paths[\"model_input\"]+\"/essays_NER.csv\"\n",
    "\n",
    "essays_entities = generate_file(tag_essays, essay_entities_file_path, create_essay_entities_file, essays, essays_metadata)\n",
    "essays_entities.entities = essays_entities.entities.apply(lambda x: literal_eval(x) )\n",
    "\n",
    "print(essays_entities.shape)\n",
    "essays_entities.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_labels_file_ = True\n",
    "if generate_labels_file_:\n",
    "    generate_labels_file(essays_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, labels, max_len, get_wids=False, labels_file_path = file_paths[\"model_input\"]):\n",
    "        self.len = len(sentences)\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.get_wids = get_wids\n",
    "        \n",
    "        with open(labels_file_path+\"/ids_to_labels.json\") as f:\n",
    "            self.ids_to_labels = {int(k):v for k,v in json.load(f).items() }\n",
    "        with open(labels_file_path+\"/labels_to_ids.json\") as f:\n",
    "            self.labels_to_ids = {k:int(v) for k,v in json.load(f).items() }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.sentences[index]\n",
    "        word_labels = self.labels[index] if not self.get_wids else None\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_offsets_mapping=True, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        \n",
    "        encoding['labels'], split_word_ids = self._get_label_ids(text, word_labels, encoding)\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        if self.get_wids: \n",
    "            item['wids'] = torch.as_tensor(split_word_ids)\n",
    "        \n",
    "        return item \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _get_label_ids(self, text, word_labels, encoding):\n",
    "        word_ids = encoding.word_ids()  \n",
    "        split_word_ids = np.full(len(word_ids),-1)\n",
    "        offset_to_wordidx = self._split_mapping(text)\n",
    "        offsets = encoding['offset_mapping']\n",
    "        \n",
    "        # CREATE TARGETS AND MAPPING OF TOKENS TO SPLIT() WORDS\n",
    "        label_ids = []\n",
    "        # Iterate in reverse to label whitespace tokens until a Begin token is encountered\n",
    "        for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n",
    "            if word_idx is None:\n",
    "                if not self.get_wids: label_ids.append(-100)\n",
    "            else:\n",
    "                if offsets[token_idx] != (0,0):\n",
    "                    #Choose the split word that shares the most characters with the token if any\n",
    "                    split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n",
    "                    split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(np.unique(split_idxs)) > 1 else split_idxs[0]\n",
    "                    \n",
    "                    if split_index != -1: \n",
    "                        if not self.get_wids: label_ids.append( self.labels_to_ids[word_labels[split_index]] )\n",
    "                        split_word_ids[token_idx] = split_index\n",
    "                    else:\n",
    "                        # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n",
    "                        last_label_id = label_ids[-1]\n",
    "                        if label_ids and last_label_id != -100 and self.ids_to_labels[last_label_id][0] == 'I':\n",
    "                            split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n",
    "                            if not self.get_wids: label_ids.append(last_label_id)\n",
    "                        else:\n",
    "                            if not self.get_wids: label_ids.append(-100)\n",
    "                else:\n",
    "                    if not self.get_wids: label_ids.append(-100)\n",
    "        \n",
    "        return list(reversed(label_ids)), split_word_ids\n",
    "\n",
    "    def _split_mapping(self, unsplit):\n",
    "        # Return an array that maps character index to index of word in list of split() words\n",
    "        # Code copied from https://www.kaggle.com/chasembowers/pytorch-bigbird-whitespace-cv-0-6284/notebook\n",
    "        splt = unsplit.split()\n",
    "        no_token_value = -1\n",
    "        offset_to_wordidx = np.full(len(unsplit), no_token_value)\n",
    "        txt_ptr = 0\n",
    "        for split_index, full_word in enumerate(splt):\n",
    "            while unsplit[txt_ptr:txt_ptr + len(full_word)] != full_word:\n",
    "                txt_ptr += 1\n",
    "            offset_to_wordidx[txt_ptr:txt_ptr + len(full_word)] = split_index\n",
    "            txt_ptr += len(full_word)\n",
    "        return offset_to_wordidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_split(data=essays_entities, split_size=0.8):\n",
    "    ids = data.id.unique()\n",
    "    print(f'There are {len(ids)} train texts.')\n",
    "    print(\"The splits will be {:.0%} train and {:.0%} validation.\".format(split_size, 1-split_size))\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(np.arange(len(ids)),int(split_size*len(ids)),replace=False)\n",
    "    valid_idx = np.setdiff1d(np.arange(len(ids)),train_idx)\n",
    "\n",
    "    # CREATE TRAIN SUBSET AND VALID SUBSET\n",
    "    data = essays_entities\n",
    "    train_data = data.loc[data['id'].isin(ids[train_idx]),['text', 'entities']].reset_index(drop=True)\n",
    "    valid_data = data.loc[data['id'].isin(ids[valid_idx])].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Full data: {data.shape}\")\n",
    "    print(f\"Tran data: {train_data.shape}\")\n",
    "    print(f\"Valid data: {valid_data.shape}\")\n",
    "\n",
    "    return train_data, valid_data\n",
    "    \n",
    "def get_data_loader(tokenizer, sentences, labels, max_len, get_wids, params):\n",
    "        if sentences is None:\n",
    "                return None\n",
    "\n",
    "        train_set = dataset(\n",
    "                tokenizer=tokenizer, \n",
    "                sentences=sentences, \n",
    "                labels=labels, \n",
    "                max_len=max_len, \n",
    "                get_wids=get_wids)\n",
    "        return DataLoader(train_set, **params)\n",
    "\n",
    "def get_data_loaders(train_data, valid_data, test_data, config):\n",
    "        train_params = {\n",
    "                'batch_size': config['train_batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 2,\n",
    "                'pin_memory':True\n",
    "        }\n",
    "\n",
    "        valid_params = {\n",
    "                'batch_size': config['valid_batch_size'],\n",
    "                'shuffle': False,\n",
    "                'num_workers': 2,\n",
    "                'pin_memory':True\n",
    "        }\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config[\"model_name\"])\n",
    "        \n",
    "        train_loader = get_data_loader(\n",
    "                tokenizer=tokenizer,\n",
    "                sentences=train_data.text,\n",
    "                labels=train_data.entities,\n",
    "                max_len=config['max_length'],\n",
    "                get_wids=False,\n",
    "                params=train_params )\n",
    "        \n",
    "        valid_loader = get_data_loader(\n",
    "                tokenizer=tokenizer,\n",
    "                sentences=valid_data.text,\n",
    "                labels=valid_data.entities,\n",
    "                max_len=config['max_length'],\n",
    "                get_wids=True,\n",
    "                params=valid_params)\n",
    "\n",
    "        test_loader = get_data_loader(\n",
    "                tokenizer=tokenizer,\n",
    "                sentences=test_data.text,\n",
    "                labels=None,\n",
    "                max_len=config['max_length'],\n",
    "                get_wids=True,\n",
    "                params=valid_params)\n",
    "\n",
    "        return train_loader, valid_loader, test_loader\n",
    "\n",
    "def get_model(config):    \n",
    "    #Model configuration \n",
    "    config_model = AutoConfig.from_pretrained(config[\"model_name\"]) \n",
    "    config_model.num_labels = 15\n",
    "\n",
    "    #Token classification model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(config[\"model_name\"], config=config_model)\n",
    "    model.to(config['device'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "def train(model, optimizer, train_loader, device_config=\"cpu\", grad_norm=10):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    #tr_preds, tr_labels = [], []\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device_config, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device_config, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device_config, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
    "                               return_dict=False)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 200==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n",
    "            wandb.log({\"step\": idx})\n",
    "            wandb.log({\"loss_step\": loss_step})\n",
    "\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        #tr_labels.extend(labels)\n",
    "        #tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=grad_norm\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msdsantiagodiez\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/sdsantiagodiez/evaluating-student-writing-kaggle-challenge/runs/3dgjidzd\" target=\"_blank\">smooth-dust-5</a></strong> to <a href=\"https://wandb.ai/sdsantiagodiez/evaluating-student-writing-kaggle-challenge\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_enabled = True\n",
    "\n",
    "wand_project = \"evaluating-student-writing-kaggle-challenge\"\n",
    "wand_entity = \"sdsantiagodiez\"\n",
    "if wandb_enabled:\n",
    "    wandb.init(project=wand_project, entity=wand_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size_proportion = 0.90\n",
    "random_seed = 42\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "model_name_alphanumeric = re.sub(\"[^0-9a-zA-Z]+\", \"_\", model_name)\n",
    "\n",
    "config = {'model_name': model_name,   \n",
    "         'max_length': 512,\n",
    "         'train_batch_size':4,\n",
    "         'valid_batch_size':4,\n",
    "         'epochs':10,\n",
    "         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "         'max_grad_norm':10,\n",
    "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts.\n",
      "The splits will be 90% train and 10% validation.\n",
      "Full data: (15594, 3)\n",
      "Tran data: (14034, 2)\n",
      "Valid data: (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = get_train_valid_split(data=essays_entities, split_size=train_set_size_proportion)\n",
    "test_data = test_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_data_loaders(train_data, valid_data, test_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model distilbert_base_uncased_v1.pt loaded.\n",
      "### Training epoch: 1\n",
      "### LR = 2.5e-05\n",
      "\n",
      "Training loss after 0000 training steps: 0.558480441570282\n",
      "Training loss after 0200 training steps: 0.522628199105239\n",
      "Training loss after 0400 training steps: 0.5311719562644673\n",
      "Training loss after 0600 training steps: 0.5325731372029928\n",
      "Training loss after 0800 training steps: 0.5433308341995012\n",
      "Training loss after 1000 training steps: 0.5451540822287897\n",
      "Training loss after 1200 training steps: 0.5483237100543329\n",
      "Training loss after 1400 training steps: 0.5485520934171544\n",
      "Training loss after 1600 training steps: 0.5499358522443382\n",
      "Training loss after 1800 training steps: 0.549999395971792\n",
      "Training loss after 2000 training steps: 0.5508328684303595\n"
     ]
    }
   ],
   "source": [
    "model_version = 1\n",
    "load_saved_model = True\n",
    "train_model = True\n",
    "\n",
    "model_file_name = f'{model_name_alphanumeric}_v{model_version}.pt'\n",
    "model_file_path = f'{file_paths[\"models\"] }/{model_name_alphanumeric}_v{model_version}.pt'\n",
    "\n",
    "if load_saved_model:\n",
    "    model.load_state_dict(torch.load(model_file_path))\n",
    "    print(f\"Model {model_file_name} loaded.\")\n",
    "\n",
    "if train_model:\n",
    "    for epoch in range(config['epochs']):\n",
    "        print(f\"### Training epoch: {epoch + 1}\")\n",
    "        for g in optimizer.param_groups: \n",
    "            g['lr'] = config['learning_rates'][epoch]\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'### LR = {lr}\\n')\n",
    "\n",
    "        train(model, optimizer, train_loader, device_config=config['device'], grad_norm=config['max_grad_norm'])    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        torch.save(model.state_dict(), model_file_path)\n",
    "    print(f\"Training complete and model {model_file_name} saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Validation Code\n",
    "\n",
    "During inference the model will make predictions for each subword token. Since a single words consists of one or more subword tokens, an approach needs to be taken in order to decide which classification to take when the model produces multiple lables for a single word\n",
    "\n",
    "In the code below, a word's first subword token prediction as the label for the entire word is the approach followed. We can try other approaches, like averaging all subword predictions or taking B labels before I labels etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(batch, device_config= \"cpu\",labels_file_path = file_paths[\"model_input\"]):\n",
    "    # MOVE BATCH TO GPU AND INFER\n",
    "    ids = batch[\"input_ids\"].to(config['device'])\n",
    "    mask = batch[\"attention_mask\"].to(config['device'])\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "    \n",
    "    with open(labels_file_path+\"/ids_to_labels.json\") as f:\n",
    "            ids_to_labels = {int(k):v for k,v in json.load(f).items() }\n",
    "    # INTERATE THROUGH EACH TEXT AND GET PRED\n",
    "    predictions = []\n",
    "    for text_pred_idx, text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][text_pred_idx].numpy()\n",
    "        previous_word_idx = -1\n",
    "        for idx, word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# https://www.kaggle.com/zzy990106/pytorch-ner-infer\n",
    "# code has been modified from original\n",
    "def get_predictions(df=valid_data, loader=valid_loader, device_config=\"cpu\"):\n",
    "    # put model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # GET WORD LABEL PREDICTIONS\n",
    "    y_pred = []\n",
    "    for batch in loader:\n",
    "        labels = inference(batch, device_config)\n",
    "        y_pred.extend(labels)\n",
    "\n",
    "    final_preds2 = []\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        idx = df.id.values[i]\n",
    "        #pred = [x.replace('B-','').replace('I-','') for x in y_pred[i]]\n",
    "        pred = y_pred[i] # Leave \"B\" and \"I\"\n",
    "        preds = []\n",
    "        j = 0\n",
    "        while j < len(pred):\n",
    "            cls = pred[j]\n",
    "            # The commented out line below appears to be a bug.\n",
    "#             if cls == 'O': j += 1\n",
    "            if cls != 'O':\n",
    "                cls = cls.replace('B','I') # spans start with B\n",
    "            end = j + 1\n",
    "            while end < len(pred) and pred[end] == cls:\n",
    "                end += 1\n",
    "            \n",
    "            if cls != 'O' and cls != '' and end - j > 7:\n",
    "                final_preds2.append((idx, cls.replace('I-',''),\n",
    "                                     ' '.join(map(str, list(range(j, end))))))\n",
    "        \n",
    "            j = end\n",
    "        \n",
    "    oof = pd.DataFrame(final_preds2)\n",
    "    oof.columns = ['id','class','predictionstring']\n",
    "\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Rob Mulla @robikscube\n",
    "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8846560846560847\n",
      "Position 0.7402684563758389\n",
      "Claim 0.5735612535612535\n",
      "Evidence 0.6588943623426382\n",
      "Concluding Statement 0.6534325889164598\n",
      "Counterclaim 0.5611300535801267\n",
      "Rebuttal 0.46479835953520166\n",
      "\n",
      "Overall 0.6481058798525148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_val_score = True\n",
    "if compute_val_score: \n",
    "    #valid data targets\n",
    "    valid_data_id_list = valid_data.id.tolist()\n",
    "    valid_data_metadata = essays_metadata.query(\"id == @valid_data_id_list\")\n",
    "    \n",
    "    # OOF PREDICTIONS\n",
    "    oof = get_predictions(valid_data, valid_loader, device_config=config[\"device\"])\n",
    "\n",
    "    # COMPUTE F1 SCORE\n",
    "    f1s = []\n",
    "    classes = oof['class'].unique()\n",
    "    print()\n",
    "    for class_ in classes:\n",
    "        pred_df = oof.loc[oof['class']==class_].copy()\n",
    "        gt_df = valid_data_metadata.query(\"discourse_type == @class_\").copy()\n",
    "        f1 = score_feedback_comp(pred_df, gt_df)\n",
    "        print(class_,f1)\n",
    "        f1s.append(f1)\n",
    "    print()\n",
    "    print('Overall',np.mean(f1s))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Position</td>\n",
       "      <td>41 42 43 44 45 46 47 48 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>50 51 52 53 54 55 56 57 58 59 60 61 62 63 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Position</td>\n",
       "      <td>89 90 91 92 93 94 95 96 97 98 99 100 101 102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  0FB0700DAF44      Lead  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...\n",
       "1  0FB0700DAF44  Position                         41 42 43 44 45 46 47 48 49\n",
       "2  0FB0700DAF44     Claim       50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n",
       "3  0FB0700DAF44     Claim       69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
       "4  0FB0700DAF44  Position       89 90 91 92 93 94 95 96 97 98 99 100 101 102"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = get_predictions(test_data, test_loader)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(file_paths[\"model_output\"]+\"/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
