{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyTorch DistilBERT NER Baseline\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Folder structure initialization\nLet's create some folders to organize our data following the [Data Engineering](https://kedro.readthedocs.io/en/stable/12_faq/01_faq.html#what-is-data-engineering-convention) standard mentioned in the [Kedro documentation](https://github.com/quantumblacklabs/kedro). Let's also store them into a dictionary so it's easier to read and use in our code","metadata":{}},{"cell_type":"code","source":"!mkdir \"/kaggle/working/data\"\n!mkdir \"/kaggle/working/data/01_raw\"\n!mkdir \"/kaggle/working/data/02_intermediate\"\n!mkdir \"/kaggle/working/data/03_primary\"\n!mkdir \"/kaggle/working/data/04_feature\"\n!mkdir \"/kaggle/working/data/05_model_input\"\n!mkdir \"/kaggle/working/data/06_models\"\n!mkdir \"/kaggle/working/data/07_model_output\"\n!mkdir \"/kaggle/working/data/08_reporting\"","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:30:12.725546Z","iopub.execute_input":"2022-01-07T14:30:12.726180Z","iopub.status.idle":"2022-01-07T14:30:18.712210Z","shell.execute_reply.started":"2022-01-07T14:30:12.726132Z","shell.execute_reply":"2022-01-07T14:30:18.711288Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"kaggle_dataset_hf_base_model = \"pydistilbertner\"\nkaggle_dataset_model = \"pydestilbertnerv1\"\nfile_paths = {\n    \n    #Kaggle's input data\n    \"train\"             : \"/kaggle/input/feedback-prize-2021/train.csv\",\n    \"sample_submission\" : \"/kaggle/input/feedback-prize-2021/sample_submission.csv\",\n    \"train_folder\"      : \"/kaggle/input/feedback-prize-2021/train\",\n    \"test_folder\"       : \"/kaggle/input/feedback-prize-2021/test\",\n    \n    #Model path for offline use during submission\n    \"hf_base\"           : \"/kaggle/input/\"+kaggle_dataset_hf_base_model,\n    \"offline_model\"     : \"/kaggle/input/\"+kaggle_dataset_model,\n    \n    #newly created data folders\n    \"raw\"               : \"/kaggle/working/data/01_raw\",\n    \"intermediate\"      : \"/kaggle/working/data/02_intermediate\",\n    \"primary\"           : \"/kaggle/working/data/03_primary\",\n    \"feature\"           : \"/kaggle/working/data/04_feature\",\n    \"model_input\"       : \"/kaggle/working/data/05_model_input\",\n    \"models\"            : \"/kaggle/working/data/06_models\",\n    \"model_output\"      : \"/kaggle/working/data/07_model_output\",\n    \"reporting\"         : \"/kaggle/working/data/08_reporting\"\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:18.714209Z","iopub.execute_input":"2022-01-07T14:30:18.714720Z","iopub.status.idle":"2022-01-07T14:30:18.722358Z","shell.execute_reply.started":"2022-01-07T14:30:18.714679Z","shell.execute_reply":"2022-01-07T14:30:18.721556Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Internet connection check\nLet's create a variable that informs if internet is enabled or not. This will be useful later in the code","metadata":{}},{"cell_type":"code","source":"import requests\n\ndef is_internet_connection_enabled():\n    url = \"http://www.kaggle.com\"\n    timeout = 5    \n    try:\n        request = requests.get(url, timeout=timeout)\n        return True\n    except (requests.ConnectionError, requests.Timeout) as exception:\n        return False\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:18.723737Z","iopub.execute_input":"2022-01-07T14:30:18.724253Z","iopub.status.idle":"2022-01-07T14:30:18.735936Z","shell.execute_reply.started":"2022-01-07T14:30:18.724218Z","shell.execute_reply":"2022-01-07T14:30:18.735163Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Weights & Biases","metadata":{}},{"cell_type":"code","source":"wandb_enabled = True\nwand_project = \"evaluating-student-writing-kaggle-challenge\"\nwand_entity = \"sdsantiagodiez\"\n\nif wandb_enabled and is_internet_connection_enabled():\n    wandb.init(project=wand_project, entity=wand_entity)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:18.738813Z","iopub.execute_input":"2022-01-07T14:30:18.739228Z","iopub.status.idle":"2022-01-07T14:30:38.764836Z","shell.execute_reply.started":"2022-01-07T14:30:18.739195Z","shell.execute_reply":"2022-01-07T14:30:38.764128Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Load data and libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys  \nimport numpy as np\nimport gc\nimport pandas as pd\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom ast import literal_eval\nimport json\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats\nimport wandb\nimport re\n\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch import cuda\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:38.767970Z","iopub.execute_input":"2022-01-07T14:30:38.768241Z","iopub.status.idle":"2022-01-07T14:30:46.453354Z","shell.execute_reply.started":"2022-01-07T14:30:38.768206Z","shell.execute_reply":"2022-01-07T14:30:46.452566Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"def read_essay(essay_id, folder_path = file_paths[\"train_folder\"]):\n    with open(folder_path + f\"/{essay_id}.txt\") as f:\n        essay = f.read()\n    return essay\n\n\ndef read_essays(train_txt):\n    train_txt_file_id, train_txt_file_text = [],[]\n    for train_txt_file in train_txt:\n        essay_id = os.path.basename(train_txt_file).rsplit(\".\",1)[0]\n        essay_folder = os.path.dirname(train_txt_file)\n\n        train_txt_file_id.append(essay_id)\n        train_txt_file_text.append(read_essay(essay_id,essay_folder))\n    return pd.DataFrame({\"id\":train_txt_file_id, \"text\":train_txt_file_text})\n\n\ndef get_essay_entities(essay_text, essay_metadata):\n    essay_entities = [\"O\"]*len(essay_text.split())\n    for discourse_type, predictionstring in zip(essay_metadata[\"discourse_type\"],essay_metadata[\"predictionstring\"]):\n        predictionstring_digits = list(map(int, predictionstring.split()))\n        \n        essay_entities[predictionstring_digits[0]] = f\"B-{discourse_type}\"\n        for predictionstring_digits_index in predictionstring_digits[1:]:\n            essay_entities[predictionstring_digits_index] = f\"I-{discourse_type}\"\n    \n    return essay_entities\n\n\ndef tag_essays(essays, essays_metadata):\n    tagged_essays = pd.DataFrame()\n    tagged_essays_list = []\n    for _, essay in essays.iterrows():\n        essay_id = essay[\"id\"]\n        essay_text = essay[\"text\"]\n        essay_metadata = essays_metadata.query(\"id == @essay_id\")\n        essay_entities = get_essay_entities(essay_text, essay_metadata)\n\n        tagged_essays_list.append( \n            {\n                \"id\": essay_id,\n                \"text\": essay_text,\n                \"entities\": essay_entities\n            }\n        )\n    return pd.DataFrame.from_dict(tagged_essays_list)\n\n\ndef generate_file(generation_func, file_path, generate_file=False, *args):\n    try:\n        if generate_file:\n            generation_func(*args).to_csv(file_path, index=False)\n        return pd.read_csv(file_path)\n    except FileNotFoundError as err:\n        print(f\"{err}, {type(err)}\")\n    except Exception as err:\n        print(f\"Unexpected {err}, {type(err)}\")\n        raise\n\ndef generate_labels_file(essays_metadata, file_path=file_paths[\"model_input\"]):\n    label_list = []\n    label_list.append('O')\n\n    for discourse_type in essays_metadata.discourse_type.unique():\n        label_list.append(f'B-{discourse_type}')\n        label_list.append(f'I-{discourse_type}')\n\n    labels_to_ids = {v:k for k,v in enumerate(label_list)}\n    ids_to_labels = {k:v for k,v in enumerate(label_list)}\n    \n    with open(file_path+\"/label_list.txt\", \"w\") as output:\n        output.write(str(label_list))\n        \n    json.dump(labels_to_ids, open(file_path+\"/labels_to_ids.json\",'w'))\n    json.dump(ids_to_labels, open(file_path+\"/ids_to_labels.json\",'w'))\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:30:46.454761Z","iopub.execute_input":"2022-01-07T14:30:46.454999Z","iopub.status.idle":"2022-01-07T14:30:46.473975Z","shell.execute_reply.started":"2022-01-07T14:30:46.454966Z","shell.execute_reply":"2022-01-07T14:30:46.472813Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"essays_metadata = pd.read_csv(file_paths[\"train\"])\nessays_metadata[['discourse_id', 'discourse_start', 'discourse_end']] = essays_metadata[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n\nsample_submission = pd.read_csv(file_paths[\"sample_submission\"])\n\n#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\ntrain_txt = glob(file_paths[\"train_folder\"] + \"/*.txt\") \ntest_txt = glob(file_paths[\"test_folder\"] + \"/*.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:46.477063Z","iopub.execute_input":"2022-01-07T14:30:46.477481Z","iopub.status.idle":"2022-01-07T14:30:48.731967Z","shell.execute_reply.started":"2022-01-07T14:30:46.477444Z","shell.execute_reply":"2022-01-07T14:30:48.731234Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"create_test_essays_file = True\nessays_file_path = file_paths[\"intermediate\"]+\"/test_text.csv\"\n\ntest_essays = generate_file(read_essays, essays_file_path, create_test_essays_file, test_txt)\n\nprint(test_essays.shape)\ntest_essays.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:48.733233Z","iopub.execute_input":"2022-01-07T14:30:48.733487Z","iopub.status.idle":"2022-01-07T14:30:48.777387Z","shell.execute_reply.started":"2022-01-07T14:30:48.733454Z","shell.execute_reply":"2022-01-07T14:30:48.776685Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"create_essays_file = True\nessays_file_path = file_paths[\"intermediate\"]+\"/train_text.csv\"\n\nessays = generate_file(read_essays, essays_file_path, create_essays_file, train_txt)\n\nprint(essays.shape)\nessays.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:30:48.778857Z","iopub.execute_input":"2022-01-07T14:30:48.779364Z","iopub.status.idle":"2022-01-07T14:31:35.214194Z","shell.execute_reply.started":"2022-01-07T14:30:48.779327Z","shell.execute_reply":"2022-01-07T14:31:35.213485Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"create_essay_entities_file = True\nessay_entities_file_path = file_paths[\"model_input\"]+\"/essays_NER.csv\"\n\nessays_entities = generate_file(tag_essays, essay_entities_file_path, create_essay_entities_file, essays, essays_metadata)\nessays_entities.entities = essays_entities.entities.apply(lambda x: literal_eval(x) )\n\nprint(essays_entities.shape)\nessays_entities.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:31:35.215483Z","iopub.execute_input":"2022-01-07T14:31:35.215914Z","iopub.status.idle":"2022-01-07T14:33:34.650022Z","shell.execute_reply.started":"2022-01-07T14:31:35.215876Z","shell.execute_reply":"2022-01-07T14:33:34.649318Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"generate_labels_file_ = True\nif generate_labels_file_:\n    generate_labels_file(essays_metadata)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:33:34.651162Z","iopub.execute_input":"2022-01-07T14:33:34.651972Z","iopub.status.idle":"2022-01-07T14:33:34.668117Z","shell.execute_reply.started":"2022-01-07T14:33:34.651932Z","shell.execute_reply":"2022-01-07T14:33:34.667417Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch & Hugging Face","metadata":{}},{"cell_type":"markdown","source":"### Classes and functions","metadata":{}},{"cell_type":"markdown","source":"#### Dataset & Dataloader definition","metadata":{}},{"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self, tokenizer, sentences, labels, max_len, get_wids=False, labels_file_path = file_paths[\"model_input\"]):\n        self.len = len(sentences)\n        self.sentences = sentences\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.get_wids = get_wids\n        \n        with open(labels_file_path+\"/ids_to_labels.json\") as f:\n            self.ids_to_labels = {int(k):v for k,v in json.load(f).items() }\n        with open(labels_file_path+\"/labels_to_ids.json\") as f:\n            self.labels_to_ids = {k:int(v) for k,v in json.load(f).items() }\n        \n    def __getitem__(self, index):\n        text = self.sentences[index]\n        word_labels = self.labels[index] if not self.get_wids else None\n        \n        encoding = self.tokenizer(\n            text,\n            return_offsets_mapping=True, \n            padding='max_length', \n            truncation=True, \n            max_length=self.max_len\n        )\n        \n        encoding['labels'], split_word_ids = self._get_label_ids(text, word_labels, encoding)\n\n        # CONVERT TO TORCH TENSORS\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        if self.get_wids: \n            item['wids'] = torch.as_tensor(split_word_ids)\n        \n        return item \n    \n    def __len__(self):\n        return self.len\n\n    def _get_label_ids(self, text, word_labels, encoding):\n        word_ids = encoding.word_ids()  \n        split_word_ids = np.full(len(word_ids),-1)\n        offset_to_wordidx = self._split_mapping(text)\n        offsets = encoding['offset_mapping']\n        \n        # CREATE TARGETS AND MAPPING OF TOKENS TO SPLIT() WORDS\n        label_ids = []\n        # Iterate in reverse to label whitespace tokens until a Begin token is encountered\n        for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n            if word_idx is None:\n                if not self.get_wids: label_ids.append(-100)\n            else:\n                if offsets[token_idx] != (0,0):\n                    #Choose the split word that shares the most characters with the token if any\n                    split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n                    split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(np.unique(split_idxs)) > 1 else split_idxs[0]\n                    \n                    if split_index != -1: \n                        if not self.get_wids: label_ids.append( self.labels_to_ids[word_labels[split_index]] )\n                        split_word_ids[token_idx] = split_index\n                    else:\n                        # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n                        last_label_id = label_ids[-1]\n                        if label_ids and last_label_id != -100 and self.ids_to_labels[last_label_id][0] == 'I':\n                            split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n                            if not self.get_wids: label_ids.append(last_label_id)\n                        else:\n                            if not self.get_wids: label_ids.append(-100)\n                else:\n                    if not self.get_wids: label_ids.append(-100)\n        \n        return list(reversed(label_ids)), split_word_ids\n\n    def _split_mapping(self, unsplit):\n        # Return an array that maps character index to index of word in list of split() words\n        # Code copied from https://www.kaggle.com/chasembowers/pytorch-bigbird-whitespace-cv-0-6284/notebook\n        splt = unsplit.split()\n        no_token_value = -1\n        offset_to_wordidx = np.full(len(unsplit), no_token_value)\n        txt_ptr = 0\n        for split_index, full_word in enumerate(splt):\n            while unsplit[txt_ptr:txt_ptr + len(full_word)] != full_word:\n                txt_ptr += 1\n            offset_to_wordidx[txt_ptr:txt_ptr + len(full_word)] = split_index\n            txt_ptr += len(full_word)\n        return offset_to_wordidx","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:33:34.669600Z","iopub.execute_input":"2022-01-07T14:33:34.669893Z","iopub.status.idle":"2022-01-07T14:33:34.691624Z","shell.execute_reply.started":"2022-01-07T14:33:34.669856Z","shell.execute_reply":"2022-01-07T14:33:34.690839Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### Get and split data","metadata":{}},{"cell_type":"code","source":"def get_train_valid_split(data=essays_entities, split_size=0.8):\n    ids = data.id.unique()\n    print(f'There are {len(ids)} train texts.')\n    print(\"The splits will be {:.0%} train and {:.0%} validation.\".format(split_size, 1-split_size))\n\n    np.random.seed(random_seed)\n    train_idx = np.random.choice(np.arange(len(ids)),int(split_size*len(ids)),replace=False)\n    valid_idx = np.setdiff1d(np.arange(len(ids)),train_idx)\n\n    # CREATE TRAIN SUBSET AND VALID SUBSET\n    data = essays_entities\n    train_data = data.loc[data['id'].isin(ids[train_idx]),['text', 'entities']].reset_index(drop=True)\n    valid_data = data.loc[data['id'].isin(ids[valid_idx])].reset_index(drop=True)\n\n    print(f\"Full data: {data.shape}\")\n    print(f\"Tran data: {train_data.shape}\")\n    print(f\"Valid data: {valid_data.shape}\")\n\n    return train_data, valid_data\n    \ndef get_data_loader(tokenizer, sentences, labels, max_len, get_wids, params):\n        if sentences is None:\n                return None\n\n        train_set = dataset(\n                tokenizer=tokenizer, \n                sentences=sentences, \n                labels=labels, \n                max_len=max_len, \n                get_wids=get_wids)\n        return DataLoader(train_set, **params)\n\ndef get_data_loaders(train_data, valid_data, test_data, config):\n        train_params = {\n                'batch_size': config['train_batch_size'],\n                'shuffle': True,\n                'num_workers': 2,\n                'pin_memory':True\n        }\n\n        valid_params = {\n                'batch_size': config['valid_batch_size'],\n                'shuffle': False,\n                'num_workers': 2,\n                'pin_memory':True\n        }\n\n        tokenizer = get_tokenizer(config)\n        \n        train_loader = get_data_loader(\n                tokenizer=tokenizer,\n                sentences=train_data.text,\n                labels=train_data.entities,\n                max_len=config['max_length'],\n                get_wids=False,\n                params=train_params )\n        \n        valid_loader = get_data_loader(\n                tokenizer=tokenizer,\n                sentences=valid_data.text,\n                labels=valid_data.entities,\n                max_len=config['max_length'],\n                get_wids=True,\n                params=valid_params)\n\n        test_loader = get_data_loader(\n                tokenizer=tokenizer,\n                sentences=test_data.text,\n                labels=None,\n                max_len=config['max_length'],\n                get_wids=True,\n                params=valid_params)\n\n        return train_loader, valid_loader, test_loader","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:33:34.693265Z","iopub.execute_input":"2022-01-07T14:33:34.693563Z","iopub.status.idle":"2022-01-07T14:33:34.708215Z","shell.execute_reply.started":"2022-01-07T14:33:34.693528Z","shell.execute_reply":"2022-01-07T14:33:34.707242Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Initializing model and tokenizer","metadata":{}},{"cell_type":"code","source":"def get_tokenizer(config):\n    if is_internet_connection_enabled():\n        tokenizer = AutoTokenizer.from_pretrained(config[\"model_name\"])\n        tokenizer.save_pretrained(file_paths[\"models\"])\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(file_paths[\"hf_base\"])\n    return tokenizer\n\ndef get_model_config(config):\n    if is_internet_connection_enabled():\n        config_model = AutoConfig.from_pretrained(config[\"model_name\"]) \n        config_model.num_labels = 15\n        config_model.save_pretrained(file_paths[\"models\"])\n    else:\n        config_model = AutoConfig.from_pretrained(file_paths[\"hf_base\"])\n    \n    return config_model\n\ndef get_model(config):    \n    config_model = get_model_config(config)\n    \n    if is_internet_connection_enabled():        \n        model = AutoModelForTokenClassification.from_pretrained(config[\"model_name\"], config=config_model)\n        model.save_pretrained(file_paths[\"models\"])\n    else:\n        model = AutoModelForTokenClassification.from_pretrained(file_paths[\"hf_base\"], config=config_model)\n    \n    model.to(config['device'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:33:34.709435Z","iopub.execute_input":"2022-01-07T14:33:34.709844Z","iopub.status.idle":"2022-01-07T14:33:34.720442Z","shell.execute_reply.started":"2022-01-07T14:33:34.709802Z","shell.execute_reply":"2022-01-07T14:33:34.719727Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Training","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ndef train(model, optimizer, train_loader, device_config=\"cpu\", grad_norm=10):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    #tr_preds, tr_labels = [], []\n    \n    # put model in training mode\n    model.train()\n    \n    for idx, batch in enumerate(train_loader):\n        \n        ids = batch['input_ids'].to(device_config, dtype = torch.long)\n        mask = batch['attention_mask'].to(device_config, dtype = torch.long)\n        labels = batch['labels'].to(device_config, dtype = torch.long)\n\n        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n                               return_dict=False)\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 200==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n            wandb.log({\"step\": idx})\n            wandb.log({\"loss_step\": loss_step})\n\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        #tr_labels.extend(labels)\n        #tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=grad_norm\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:33:34.721788Z","iopub.execute_input":"2022-01-07T14:33:34.722266Z","iopub.status.idle":"2022-01-07T14:33:34.736306Z","shell.execute_reply.started":"2022-01-07T14:33:34.722230Z","shell.execute_reply":"2022-01-07T14:33:34.735521Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### Inference and Validation Code\n\nDuring inference the model will make predictions for each subword token. Since a single words consists of one or more subword tokens, an approach needs to be taken in order to decide which classification to take when the model produces multiple lables for a single word\n\nIn the code below, a word's first subword token prediction as the label for the entire word is the approach followed. We can try other approaches, like averaging all subword predictions or taking B labels before I labels etc.","metadata":{}},{"cell_type":"code","source":"def inference(batch, device_config= \"cpu\",labels_file_path = file_paths[\"model_input\"]):\n    # MOVE BATCH TO GPU AND INFER\n    ids = batch[\"input_ids\"].to(config['device'])\n    mask = batch[\"attention_mask\"].to(config['device'])\n    outputs = model(ids, attention_mask=mask, return_dict=False)\n    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n    \n    with open(labels_file_path+\"/ids_to_labels.json\") as f:\n            ids_to_labels = {int(k):v for k,v in json.load(f).items() }\n    # INTERATE THROUGH EACH TEXT AND GET PRED\n    predictions = []\n    for text_pred_idx, text_preds in enumerate(all_preds):\n        token_preds = [ids_to_labels[i] for i in text_preds]\n\n        prediction = []\n        word_ids = batch['wids'][text_pred_idx].numpy()\n        previous_word_idx = -1\n        for idx, word_idx in enumerate(word_ids):                            \n            if word_idx == -1:\n                pass\n            elif word_idx != previous_word_idx:              \n                prediction.append(token_preds[idx])\n                previous_word_idx = word_idx\n        predictions.append(prediction)\n    \n    return predictions\n\n# https://www.kaggle.com/zzy990106/pytorch-ner-infer\n# code has been modified from original\ndef get_predictions(df, loader, device_config=\"cpu\"):\n    # put model in eval mode\n    model.eval()\n    \n    # GET WORD LABEL PREDICTIONS\n    y_pred = []\n    for batch in loader:\n        labels = inference(batch, device_config)\n        y_pred.extend(labels)\n\n    final_preds2 = []\n    for i in range(len(df)):\n\n        idx = df.id.values[i]\n        #pred = [x.replace('B-','').replace('I-','') for x in y_pred[i]]\n        pred = y_pred[i] # Leave \"B\" and \"I\"\n        preds = []\n        j = 0\n        while j < len(pred):\n            cls = pred[j]\n            # The commented out line below appears to be a bug.\n#             if cls == 'O': j += 1\n            if cls != 'O':\n                cls = cls.replace('B','I') # spans start with B\n            end = j + 1\n            while end < len(pred) and pred[end] == cls:\n                end += 1\n            \n            if cls != 'O' and cls != '' and end - j > 7:\n                final_preds2.append((idx, cls.replace('I-',''),\n                                     ' '.join(map(str, list(range(j, end))))))\n        \n            j = end\n        \n    oof = pd.DataFrame(final_preds2)\n    oof.columns = ['id','class','predictionstring']\n\n    return oof","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:33:34.737923Z","iopub.execute_input":"2022-01-07T14:33:34.738730Z","iopub.status.idle":"2022-01-07T14:33:34.754957Z","shell.execute_reply.started":"2022-01-07T14:33:34.738690Z","shell.execute_reply":"2022-01-07T14:33:34.754207Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Score feedback competition calc","metadata":{}},{"cell_type":"code","source":"# from Rob Mulla @robikscube\n# https://www.kaggle.com/robikscube/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-07T14:33:34.758913Z","iopub.execute_input":"2022-01-07T14:33:34.759627Z","iopub.status.idle":"2022-01-07T14:33:34.775276Z","shell.execute_reply.started":"2022-01-07T14:33:34.759587Z","shell.execute_reply":"2022-01-07T14:33:34.774504Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Model training and prediction","metadata":{}},{"cell_type":"code","source":"train_set_size_proportion = 0.90\nrandom_seed = 42\n\nmodel_name = 'distilbert-base-uncased'\nmodel_name_alphanumeric = re.sub(\"[^0-9a-zA-Z]+\", \"_\", model_name)\n\nconfig = {'model_name': model_name,   \n         'max_length': 512,\n         'train_batch_size':4,\n         'valid_batch_size':4,\n         'epochs':10,\n         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n         'max_grad_norm':10,\n         'device': 'cuda' if cuda.is_available() else 'cpu'}","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:33:34.776636Z","iopub.execute_input":"2022-01-07T14:33:34.777346Z","iopub.status.idle":"2022-01-07T14:33:34.826778Z","shell.execute_reply.started":"2022-01-07T14:33:34.777309Z","shell.execute_reply":"2022-01-07T14:33:34.826023Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data = get_train_valid_split(data=essays_entities, split_size=train_set_size_proportion)\ntest_data = test_essays","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:33:34.828502Z","iopub.execute_input":"2022-01-07T14:33:34.828984Z","iopub.status.idle":"2022-01-07T14:33:34.861342Z","shell.execute_reply.started":"2022-01-07T14:33:34.828923Z","shell.execute_reply":"2022-01-07T14:33:34.860671Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_data_loaders(train_data, valid_data, test_data, config)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:37:57.136243Z","iopub.execute_input":"2022-01-07T14:37:57.136526Z","iopub.status.idle":"2022-01-07T14:38:17.241293Z","shell.execute_reply.started":"2022-01-07T14:37:57.136497Z","shell.execute_reply":"2022-01-07T14:38:17.240551Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = get_model(config)\noptimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rates'][0])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:38:20.764837Z","iopub.execute_input":"2022-01-07T14:38:20.765477Z","iopub.status.idle":"2022-01-07T14:39:10.932557Z","shell.execute_reply.started":"2022-01-07T14:38:20.765441Z","shell.execute_reply":"2022-01-07T14:39:10.931836Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model_version = 1\nload_saved_model = True\ntrain_model = False\n\nmodel_file_name = f'{model_name_alphanumeric}_v{model_version}.pt'\nmodel_file_path = f'{file_paths[\"offline_model\"] }/{model_name_alphanumeric}_v{model_version}.pt'\n\nif load_saved_model:\n    model.load_state_dict(torch.load(model_file_path))\n    print(f\"Model {model_file_name} loaded.\")\n\nif train_model:\n    for epoch in range(config['epochs']):\n        print(f\"### Training epoch: {epoch + 1}\")\n        wandb.log({\"epoch\": epoch + 1})\n        \n        lr = learning_rates[epoch] if epoch < len(learning_rates) else learning_rates[-1]\n        for g in optimizer.param_groups: \n            g['lr'] = lr\n        print(f'### LR = {lr}\\n')\n\n        train(model, optimizer, train_loader, device_config=config['device'], grad_norm=config['max_grad_norm'])    \n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        torch.save(model.state_dict(), model_file_path)\n    print(f\"Training complete and model {model_file_name} saved.\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:41:01.367475Z","iopub.execute_input":"2022-01-07T14:41:01.367750Z","iopub.status.idle":"2022-01-07T14:41:05.833547Z","shell.execute_reply.started":"2022-01-07T14:41:01.367721Z","shell.execute_reply":"2022-01-07T14:41:05.832792Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"compute_val_score = True\nif compute_val_score: \n    #valid data targets\n    valid_data_id_list = valid_data.id.tolist()\n    valid_data_metadata = essays_metadata.query(\"id == @valid_data_id_list\")\n    \n    # OOF PREDICTIONS\n    oof = get_predictions(valid_data, valid_loader, device_config=config[\"device\"])\n\n    # COMPUTE F1 SCORE\n    f1s = []\n    classes = oof['class'].unique()\n    print()\n    for class_ in classes:\n        pred_df = oof.loc[oof['class']==class_].copy()\n        gt_df = valid_data_metadata.query(\"discourse_type == @class_\").copy()\n        f1 = score_feedback_comp(pred_df, gt_df)\n        print(class_,f1)\n        f1s.append(f1)\n    print()\n    print('Overall',np.mean(f1s))\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:41:28.303413Z","iopub.execute_input":"2022-01-07T14:41:28.303665Z","iopub.status.idle":"2022-01-07T14:41:50.205786Z","shell.execute_reply.started":"2022-01-07T14:41:28.303636Z","shell.execute_reply":"2022-01-07T14:41:50.205035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"sub = get_predictions(test_data, test_loader)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:47:53.079129Z","iopub.execute_input":"2022-01-07T14:47:53.079857Z","iopub.status.idle":"2022-01-07T14:47:53.340895Z","shell.execute_reply.started":"2022-01-07T14:47:53.079819Z","shell.execute_reply":"2022-01-07T14:47:53.340045Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(file_paths[\"model_output\"]+\"/submission.csv\", index=False)\nsub.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}